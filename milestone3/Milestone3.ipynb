{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hmRzIDdKygE",
        "outputId": "e80fd00d-4624-4642-8895-6c09b186ad90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m239.2/239.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Section 1 ‚Äì Install & Import Dependencies\n",
        "!pip install streamlit pyngrok bcrypt pyjwt pandas nltk textstat --quiet\n",
        "# Install Hugging Face Transformers and Pytorch (or Tensorflow if preferred)\n",
        "!pip install transformers torch sentencepiece rouge_score --quiet\n",
        "\n",
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# Set up your ngrok authtoken (REPLACE this with your actual token!)\n",
        "!ngrok config add-authtoken 34ShfKeTV8CoS2zyEOQ5ynOTeEe_68W9dTvLEEgEnbF5hQxdh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import bcrypt\n",
        "import pandas as pd\n",
        "import jwt\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import nltk\n",
        "from textstat import textstat\n",
        "import random\n",
        "import torch\n",
        "from transformers import pipeline, BartForConditionalGeneration, BartTokenizer, PegasusForConditionalGeneration, PegasusTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
        "from rouge_score import rouge_scorer\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "# --- Global Configurations ---\n",
        "SECRET_KEY = \"your-long-and-very-secret-key-for-jwt-goes-here\"\n",
        "MOCK_OTP_DURATION_MINUTES = 5\n",
        "\n",
        "# --- NLTK Downloads (ensure they run once) ---\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# --- 1. Page Configuration & Custom CSS (Light Colors/Better UI) ---\n",
        "st.set_page_config(\n",
        "    page_title=\"LLM AI\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "# New CSS for a softer, lighter design and specific Module 2 features\n",
        "custom_css = \"\"\"\n",
        "<style>\n",
        "    /* Global Container */\n",
        "    .main .block-container {\n",
        "        max-width: 1200px;\n",
        "        padding-top: 2rem;\n",
        "    }\n",
        "    /* Header/Title Bar */\n",
        "    h1 {\n",
        "        background: linear-gradient(135deg, rgba(13, 109, 253, 0.8), rgba(147, 112, 219, 0.8), rgba(255, 105, 180, 0.8), rgba(238, 130, 238, 0.8));\n",
        "        color: white; /* Changed text color to white for better contrast */\n",
        "        padding: 1.5rem; /* Increased padding */\n",
        "        border-radius: 15px; /* More rounded corners */\n",
        "        text-align: center; /* Centered text */\n",
        "        font-size: 30px; /* Larger font size */\n",
        "        margin-bottom: 2rem !important; /* Increased margin */\n",
        "        border-left: none; /* Removed left border */\n",
        "        backdrop-filter: blur(10px); /* Glassy effect */\n",
        "        -webkit-backdrop-filter: blur(10px); /* Safari support */\n",
        "        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15); /* More prominent shadow */\n",
        "        border: 1px solid rgba(255, 255, 255, 0.3); /* Light border */\n",
        "    }\n",
        "    /* General Card/Form Container */\n",
        "    div[data-testid=\"stTabs\"], .score-card, .key-features, .upload-area, .output-card {\n",
        "        border: 1px solid rgba(201, 210, 242, 0.5); /* Adjusted border color with transparency */\n",
        "        border-radius: 15px; /* More rounded corners */\n",
        "        padding: 2rem; /* Increased padding */\n",
        "        box-shadow: 0 6px 18px rgba(0, 0, 0, 0.08); /* Adjusted shadow */\n",
        "        background-color: rgba(255, 255, 255, 0.6); /* Semi-transparent white background */\n",
        "        backdrop-filter: blur(5px); /* Subtle glassy effect */\n",
        "        -webkit-backdrop-filter: blur(5px); /* Safari support */\n",
        "    }\n",
        "    /* Button Style (Primary Blue) */\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background: linear-gradient(45deg, #0d6efd, #6610f2); /* Gradient button */\n",
        "        color: white;\n",
        "        border-radius: 8px; /* More rounded buttons */\n",
        "        border: none;\n",
        "        margin: 5px 0;\n",
        "        transition: all 0.3s ease; /* Smooth transition */\n",
        "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background: linear-gradient(45deg, #0b5ed7, #550acc); /* Darker gradient on hover */\n",
        "        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2);\n",
        "    }\n",
        "     /* OTP Success/Error */\n",
        "    div[data-testid=\"stSuccess\"], div[data-testid=\"stError\"] {\n",
        "        border-radius: 8px;\n",
        "    }\n",
        "    /* Readability Scores/Progress Bars (Improved Visuals) */\n",
        "    .score-card {\n",
        "        padding: 1.5rem; /* Increased padding */\n",
        "        background-color: rgba(247, 249, 255, 0.7); /* Semi-transparent light background */\n",
        "        margin-bottom: 15px; /* Increased margin */\n",
        "        border-radius: 12px; /* Rounded corners */\n",
        "        backdrop-filter: blur(4px); /* Subtle glassy effect */\n",
        "        -webkit-backdrop-filter: blur(4px); /* Safari support */\n",
        "        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);\n",
        "    }\n",
        "    .score-value { font-size: 2.5em; font-weight: bold; color: #1e3a8a; }\n",
        "    .score-label { font-size: 1em; color: #4b5563; margin-top: 5px; }\n",
        "\n",
        "    /* Complexity Chart Colors (Matching visual cues) */\n",
        "    .stBarChart { opacity: 0.9; }\n",
        "\n",
        "    /* New: Specific style for the mock code warning */\n",
        "    .mock-code-warning {\n",
        "        background-color: #ffe0b2; /* Light orange/amber */\n",
        "        color: #ff9800; /* Darker orange text */\n",
        "        padding: 10px;\n",
        "        border-radius: 8px;\n",
        "        border-left: 5px solid #ff9800;\n",
        "        margin-top: 10px;\n",
        "        font-weight: bold;\n",
        "        font-size: 1.1em;\n",
        "    }\n",
        "\n",
        "     /* Input fields */\n",
        "    .stTextInput>div>div>input, .stTextArea>div>div>textarea {\n",
        "        background-color: rgba(255, 255, 255, 0.7);\n",
        "        border-radius: 8px;\n",
        "        border: 1px solid #c9d2f2;\n",
        "        padding: 10px;\n",
        "    }\n",
        "\n",
        "    /* Select boxes */\n",
        "    .stSelectbox>div>div>div>div {\n",
        "         background-color: rgba(255, 255, 255, 0.7);\n",
        "         border-radius: 8px;\n",
        "         border: 1px solid #c9d2f2;\n",
        "         padding: 5px 10px;\n",
        "    }\n",
        "\n",
        "    /* Progress bar colors for readability */\n",
        "    .progress-bar-container {\n",
        "        width: 100%;\n",
        "        background-color: #e0e0e0;\n",
        "        border-radius: 5px;\n",
        "        margin-top: 10px;\n",
        "        overflow: hidden; /* Ensures the inner bar stays within bounds */\n",
        "    }\n",
        "\n",
        "    .progress-bar {\n",
        "        height: 8px;\n",
        "        border-radius: 5px;\n",
        "        transition: width 0.5s ease-in-out;\n",
        "    }\n",
        "\n",
        "    /* Green for easy (high Flesch Ease, low grade indices) */\n",
        "    .fe-green .progress-bar, .fk-green .progress-bar, .gf-green .progress-bar, .smog-green .progress-bar {\n",
        "        background-color: #28a745;\n",
        "    }\n",
        "\n",
        "    /* Yellow/Orange for intermediate */\n",
        "    .fe-yellow .progress-bar, .fk-yellow .progress-bar, .gf-yellow .progress-bar, .smog-yellow .progress-bar {\n",
        "        background-color: #ffc107;\n",
        "    }\n",
        "\n",
        "    /* Red for difficult (low Flesch Ease, high grade indices) */\n",
        "    .fe-red .progress-bar, .fk-red .progress-bar, .gf-red .progress-bar, .smog-red .progress-bar {\n",
        "        background-color: #dc3545;\n",
        "    }\n",
        "\n",
        "    /* Radar chart customization (handled by Plotly, but ensuring container styling doesn't interfere) */\n",
        "    .stPlotlyChart {\n",
        "        background-color: rgba(255, 255, 255, 0.6); /* Match card background */\n",
        "        border-radius: 12px;\n",
        "        padding: 15px;\n",
        "        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);\n",
        "         backdrop-filter: blur(4px);\n",
        "        -webkit-backdrop-filter: blur(4px);\n",
        "    }\n",
        "\n",
        "\n",
        "</style>\n",
        "\"\"\"\n",
        "st.markdown(custom_css, unsafe_allow_html=True)\n",
        "\n",
        "# =============================================================================\n",
        "#  2. DATABASE AND AUTHENTICATION BACKEND FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def init_db():\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # 1. Create table with all columns (for new DBs)\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            email TEXT PRIMARY KEY,\n",
        "            username TEXT,\n",
        "            password_hash BLOB NOT NULL,\n",
        "            role TEXT NOT NULL\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # 2. Database Migration Check (Ensuring 'username' column exists)\n",
        "    try:\n",
        "        # Check if the 'username' column exists and is populated\n",
        "        c.execute(\"SELECT username FROM users LIMIT 1\")\n",
        "    except sqlite3.OperationalError:\n",
        "        # If the column doesn't exist (old schema), add it\n",
        "        c.execute(\"ALTER TABLE users ADD COLUMN username TEXT\")\n",
        "\n",
        "    # 3. Update existing users (like the default admin) to have a username\n",
        "    c.execute(\"UPDATE users SET username = 'AdminUser' WHERE email='admin@ai' AND username IS NULL\")\n",
        "\n",
        "    # 4. Add default admin user if not exists (using the correct, complete column list)\n",
        "    c.execute(\"SELECT * FROM users WHERE email='admin@ai'\")\n",
        "    if not c.fetchone():\n",
        "        admin_email, admin_pass, admin_username = \"admin@ai\", \"Infosys\", \"AdminUser\"\n",
        "        hashed_pass = bcrypt.hashpw(admin_pass.encode(), bcrypt.gensalt())\n",
        "        c.execute(\"INSERT INTO users (email, username, password_hash, role) VALUES (?, ?, ?, ?)\", (admin_email, admin_username, hashed_pass, \"Admin\"))\n",
        "\n",
        "    # OTP table\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS password_resets (\n",
        "            email TEXT PRIMARY KEY,\n",
        "            otp TEXT NOT NULL,\n",
        "            expiry_time TIMESTAMP NOT NULL\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_all_users():\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    df = pd.read_sql_query(\"SELECT email, username, role FROM users\", conn)\n",
        "    conn.close()\n",
        "    return df\n",
        "\n",
        "def delete_user(email):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"DELETE FROM users WHERE email=?\", (email,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def user_exists(email):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT email FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "    return result is not None\n",
        "\n",
        "def update_password(email, new_password):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    hashed_password = bcrypt.hashpw(new_password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"UPDATE users SET password_hash = ? WHERE email = ?\", (hashed_password, email))\n",
        "    # Clear the OTP record after successful reset\n",
        "    c.execute(\"DELETE FROM password_resets WHERE email=?\", (email,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return \"Password updated successfully!\"\n",
        "\n",
        "def verify_password(plain_password, hashed_password):\n",
        "    return bcrypt.checkpw(plain_password.encode('utf-8'), hashed_password)\n",
        "\n",
        "def register_user(email, username, password, role=\"General User\"):\n",
        "    if len(password) < 6:\n",
        "        return \"Password must be at least 6 characters long.\"\n",
        "    if not username.strip():\n",
        "        return \"Username cannot be empty.\"\n",
        "\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Check if email already exists.\n",
        "    c.execute(\"SELECT * FROM users WHERE email=?\", (email,))\n",
        "    if c.fetchone(): conn.close(); return \"Email already exists.\"\n",
        "\n",
        "    # Check if username already exists.\n",
        "    c.execute(\"SELECT * FROM users WHERE username=?\", (username,))\n",
        "    if c.fetchone(): conn.close(); return \"Username already exists.\"\n",
        "\n",
        "    hashed_password = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())\n",
        "    c.execute(\"INSERT INTO users (email, username, password_hash, role) VALUES (?, ?, ?, ?)\", (email, username, hashed_password, role))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return \"User registered successfully! Please log in.\"\n",
        "\n",
        "def generate_token(email, role):\n",
        "    payload = {'exp': datetime.utcnow() + timedelta(hours=1), 'iat': datetime.utcnow(), 'sub': email, 'role': role}\n",
        "    return jwt.encode(payload, SECRET_KEY, algorithm='HS256')\n",
        "\n",
        "def decode_token(token):\n",
        "    try: return jwt.decode(token, SECRET_KEY, algorithms=['HS256'])\n",
        "    except: return None\n",
        "\n",
        "def authenticate_user(email, password):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT password_hash, role FROM users WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "    if result:\n",
        "        hashed_password_from_db, role = result\n",
        "        if verify_password(password, hashed_password_from_db):\n",
        "            return generate_token(email, role)\n",
        "    return None\n",
        "\n",
        "# --- Mock OTP Functions ---\n",
        "def generate_and_store_otp(email):\n",
        "    otp = str(random.randint(100000, 999999))\n",
        "    expiry_time = datetime.utcnow() + timedelta(minutes=MOCK_OTP_DURATION_MINUTES)\n",
        "\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"REPLACE INTO password_resets (email, otp, expiry_time) VALUES (?, ?, ?)\", (email, otp, expiry_time))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return otp\n",
        "\n",
        "def verify_otp(email, otp):\n",
        "    conn = sqlite3.connect('llm_users.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT otp, expiry_time FROM password_resets WHERE email=?\", (email,))\n",
        "    result = c.fetchone()\n",
        "    conn.close()\n",
        "\n",
        "    if result:\n",
        "        stored_otp, expiry_time_str = result\n",
        "        try:\n",
        "            expiry_time = datetime.fromisoformat(expiry_time_str)\n",
        "        except ValueError:\n",
        "            expiry_time = datetime.strptime(expiry_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
        "\n",
        "        if stored_otp == otp and datetime.utcnow() < expiry_time:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#  3. NLP Model Management (Mock/Load)\n",
        "# =============================================================================\n",
        "\n",
        "@st.cache_resource\n",
        "def load_summarization_model(model_name):\n",
        "    st.info(f\"Loading {model_name}...\")\n",
        "    try:\n",
        "        # Load small/base models for faster response in a demo setting\n",
        "        if model_name == \"BART\":\n",
        "            model = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0 if torch.cuda.is_available() else -1)\n",
        "        elif model_name == \"Pegasus\":\n",
        "            model = pipeline(\"summarization\", model=\"google/pegasus-xsum\", device=0 if torch.cuda.is_available() else -1)\n",
        "        elif model_name == \"FLAN-T5\":\n",
        "            model = pipeline(\"summarization\", model=\"google/flan-t5-small\", device=0 if torch.cuda.is_available() else -1)\n",
        "        else:\n",
        "            return None\n",
        "        st.success(f\"{model_name} loaded.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading {model_name}: {e}. Ensure you have installed the models correctly.\")\n",
        "        return None\n",
        "\n",
        "@st.cache_resource\n",
        "def load_paraphrasing_model(model_name):\n",
        "    st.info(f\"Loading {model_name} for paraphrasing...\")\n",
        "    try:\n",
        "        if model_name == \"FLAN-T5 (Paraphrase)\":\n",
        "            model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
        "            tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "        elif model_name == \"BART (Paraphrase)\":\n",
        "            model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
        "            tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
        "        else:\n",
        "            return None, None\n",
        "        st.success(f\"{model_name} loaded.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading {model_name}: {e}. Ensure you have installed the models correctly.\")\n",
        "        return None, None\n",
        "\n",
        "# =============================================================================\n",
        "#  4. READABILITY ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "def calculate_readability_scores(text):\n",
        "    \"\"\"Calculates multiple readability scores for the given text.\"\"\"\n",
        "    if not text.strip(): return None, None, None, None\n",
        "    clean_text = re.sub(r'[^a-zA-Z0-9\\s.,;\\'\"!?()]', '', text)\n",
        "    if not clean_text.strip(): return None, None, None, None\n",
        "    try:\n",
        "        flesch_kincaid = textstat.flesch_kincaid_grade(clean_text)\n",
        "        gunning_fog = textstat.gunning_fog(clean_text)\n",
        "        smog_index = textstat.smog_index(clean_text)\n",
        "        flesch_reading_ease = textstat.flesch_reading_ease(clean_text)\n",
        "    except Exception as e:\n",
        "        return None, None, None, None\n",
        "    return flesch_kincaid, gunning_fog, smog_index, flesch_reading_ease\n",
        "\n",
        "def get_score_color_class(score, index_type='flesch_kincaid'):\n",
        "    \"\"\"Returns a CSS class based on the score range for visual feedback.\"\"\"\n",
        "    if score is None: return \"\"\n",
        "    if index_type == 'flesch_kincaid':\n",
        "        if score <= 5: return \"fk-green\"    # Very Easy\n",
        "        elif score <= 10: return \"fk-yellow\" # Intermediate\n",
        "        else: return \"fk-red\"               # Complex\n",
        "    elif index_type == 'gunning_fog':\n",
        "        if score <= 8: return \"gf-green\"\n",
        "        elif score <= 12: return \"gf-yellow\"\n",
        "        else: return \"gf-red\"\n",
        "    elif index_type == 'smog_index':\n",
        "        if score <= 8: return \"smog-green\"\n",
        "        elif score <= 12: return \"smog-yellow\"\n",
        "        else: return \"smog-red\"\n",
        "    elif index_type == 'flesch_ease':\n",
        "        if score >= 90: return \"fe-green\"    # Very Easy\n",
        "        elif score >= 60: return \"fe-yellow\" # Standard\n",
        "        else: return \"fe-red\"                # Difficult\n",
        "    return \"\"\n",
        "\n",
        "def display_score_card(label, score, max_val, index_type):\n",
        "    \"\"\"Displays an enhanced, color-coded score card.\"\"\"\n",
        "    score_display = f\"{score:.1f}\" if score is not None else \"N/A\"\n",
        "\n",
        "    if index_type == 'flesch_ease':\n",
        "        max_val_progress = 100\n",
        "        progress_percent = (score / max_val_progress * 100) if score is not None else 0\n",
        "    else:\n",
        "        max_val_progress = 20\n",
        "        if score is not None:\n",
        "            capped_score = min(score, max_val_progress)\n",
        "            # Invert progress bar for grade levels: 0 score (easiest) = 100% progress\n",
        "            progress_percent = (1 - (capped_score / max_val_progress)) * 100\n",
        "        else:\n",
        "            progress_percent = 0\n",
        "\n",
        "    color_class = get_score_color_class(score, index_type)\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "    <div class=\"score-card {color_class}\">\n",
        "        <div class=\"score-value\">{score_display}</div>\n",
        "        <div class=\"score-label\">{label}</div>\n",
        "        <div class=\"progress-bar-container\">\n",
        "            <div class=\"progress-bar\" style=\"width: {progress_percent:.1f}%;\"></div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ¬†5. UI SECTION: READABILITY ANALYSIS (Updated with Plotly Radar Chart)\n",
        "# =============================================================================\n",
        "def readability_analysis_ui():\n",
        "    \"\"\"Renders the professional readability analysis dashboard UI.\"\"\"\n",
        "    st.markdown(\"<h1>üìà Document Readability Dashboard</h1>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"Analyze the complexity and grade level of your text using industry-standard metrics.\", unsafe_allow_html=True)\n",
        "\n",
        "    # --- Input Area ---\n",
        "    st.markdown(\"\"\"<div class=\"upload-area\"><h3>Text Input for Analysis</h3></div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload a text document (.txt) or a simple PDF/DOCX for extraction attempt.\", type=[\"txt\", \"pdf\", \"docx\"], label_visibility=\"collapsed\", key=\"readability_file\")\n",
        "\n",
        "    col_text, col_button = st.columns([6, 1])\n",
        "    with col_text:\n",
        "        text_input = st.text_area(\"Paste your content here\", height=200, help=\"Enter text directly for full readability analysis.\", key=\"readability_text_input\")\n",
        "    with col_button:\n",
        "        st.markdown(\"<div style='height: 155px;'></div>\", unsafe_allow_html=True)\n",
        "        analyze_button = st.button(\"Analyze Content\", key=\"run_readability_analysis\", use_container_width=True)\n",
        "\n",
        "    content_to_analyze = \"\"\n",
        "    run_analysis_flag = False\n",
        "\n",
        "    # Logic to process input and trigger analysis (kept simple for focus)\n",
        "    if analyze_button or uploaded_file is not None:\n",
        "        if analyze_button and text_input:\n",
        "            content_to_analyze = text_input\n",
        "            run_analysis_flag = True\n",
        "        elif uploaded_file is not None:\n",
        "            try:\n",
        "                if uploaded_file.type == \"text/plain\":\n",
        "                    content_to_analyze = uploaded_file.read().decode(\"utf-8\")\n",
        "                    run_analysis_flag = True\n",
        "                else:\n",
        "                    st.warning(\"Using sample text for complexity demonstration.\")\n",
        "                    content_to_analyze = \"The complex nexus of computational and theoretical frameworks necessitates a multi-modal approach to extant problematics, which are often non-linear and require significant, interdisciplinary expertise.\"\n",
        "                    run_analysis_flag = True\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error reading file: {e}\")\n",
        "                run_analysis_flag = False\n",
        "        elif analyze_button and not text_input:\n",
        "             st.warning(\"Please paste text or upload a file to analyze.\")\n",
        "\n",
        "    # Store analyzed content in session state for persistence\n",
        "    if run_analysis_flag:\n",
        "        st.session_state.analyzed_content = content_to_analyze\n",
        "        st.session_state.readability_run = True\n",
        "    elif not analyze_button and uploaded_file is None:\n",
        "        if 'readability_run' in st.session_state:\n",
        "             st.session_state.readability_run = False\n",
        "        if 'analyzed_content' in st.session_state:\n",
        "            st.session_state.analyzed_content = \"\"\n",
        "\n",
        "    # --- Output Area ---\n",
        "    if st.session_state.get('readability_run') and st.session_state.get('analyzed_content'):\n",
        "        content_to_analyze = st.session_state.analyzed_content\n",
        "        fk_grade, gunning_fog, smog_index, flesch_ease = calculate_readability_scores(content_to_analyze)\n",
        "        word_count = len(content_to_analyze.split())\n",
        "\n",
        "        # --- Score Cards Section ---\n",
        "        st.subheader(\"Key Readability Metrics üéØ\")\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "        with col1:\n",
        "            display_score_card(\"F-K Grade Level\", fk_grade, 18, 'flesch_kincaid')\n",
        "        with col2:\n",
        "            display_score_card(\"Gunning Fog Index\", gunning_fog, 20, 'gunning_fog')\n",
        "        with col3:\n",
        "            display_score_card(\"SMOG Grade Index\", smog_index, 20, 'smog_index')\n",
        "        with col4:\n",
        "            display_score_card(\"Flesch Reading Ease\", flesch_ease, 100, 'flesch_ease')\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        # --- Complexity Level & RADAR Chart ---\n",
        "        st.subheader(\"Readability Profile Visualization (Radar Chart) üìä\")\n",
        "\n",
        "        if fk_grade is not None and flesch_ease is not None:\n",
        "\n",
        "            # Determine complexity level for the header\n",
        "            if fk_grade <= 5: level = \"Elementary School (K-5)\"; color = '#28a745'\n",
        "            elif fk_grade <= 8: level = \"Middle School (6-8)\"; color = '#ffc107'\n",
        "            elif fk_grade <= 12: level = \"High School (9-12)\"; color = '#fd7e14'\n",
        "            else: level = \"College / Post-Graduate\"; color = '#dc3545'\n",
        "\n",
        "            st.markdown(f\"\"\"\n",
        "                <div style='text-align:center; padding: 15px; background-color:{color}; color:white; border-radius:10px; margin-bottom: 20px;'>\n",
        "                    <h4>Estimated Audience Level: <b>{level}</b></h4>\n",
        "                    <p>Flesch-Kincaid Grade: {fk_grade:.1f} | Flesch Reading Ease: {flesch_ease:.1f}</p>\n",
        "                </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "            # --- Plotly Radar Chart Implementation ---\n",
        "\n",
        "            # 1. Normalize scores to a 0-100 scale for a unified radar chart.\n",
        "            # We want the HIGHER score (closer to the edge) to mean EASIER text.\n",
        "\n",
        "            # Grade-level indices (FK, GF, SMOG): Lower is easier. Max cap at 15 for visualization.\n",
        "            # Normalized Score = 100 - (Actual Score / 15) * 100\n",
        "            fk_norm = max(0, min(100, 100 - (fk_grade / 15) * 100))\n",
        "            gf_norm = max(0, min(100, 100 - (gunning_fog / 15) * 100))\n",
        "            smog_norm = max(0, min(100, 100 - (smog_index / 15) * 100))\n",
        "\n",
        "            # Flesch Reading Ease (FE): Higher is easier. Max cap at 100.\n",
        "            # Normalized Score = Actual Score\n",
        "            fe_norm = max(0, min(100, flesch_ease))\n",
        "\n",
        "            # Create a DataFrame for Plotly (must be long format)\n",
        "            chart_data = pd.DataFrame(dict(\n",
        "                r=[fe_norm, fk_norm, gf_norm, smog_norm],\n",
        "                theta=['Flesch Ease (100=Easy)', 'F-K Grade (100=Easy)', 'Gunning Fog (100=Easy)', 'SMOG Index (100=Easy)'],\n",
        "                actual_score=[f'{flesch_ease:.1f}', f'{fk_grade:.1f}', f'{gunning_fog:.1f}', f'{smog_index:.1f}']\n",
        "            ))\n",
        "\n",
        "            fig = px.line_polar(chart_data,\n",
        "                                r='r',\n",
        "                                theta='theta',\n",
        "                                line_close=True,\n",
        "                                color_discrete_sequence=['#4c78a8'] # Single color line for a profile plot\n",
        "                               )\n",
        "\n",
        "            # Customizing the Plotly Radar Chart\n",
        "            fig.update_traces(fill='toself', name='Your Text')\n",
        "            fig.update_layout(\n",
        "                polar=dict(\n",
        "                    radialaxis=dict(\n",
        "                        visible=True,\n",
        "                        range=[0, 100],\n",
        "                        tickvals=[0, 25, 50, 75, 100],\n",
        "                        ticktext=['Hard (0)', 'Difficult (25)', 'Standard (50)', 'Easy (75)', 'Very Easy (100)'],\n",
        "                        showline=True,\n",
        "                        linecolor='gray'\n",
        "                    )),\n",
        "                showlegend=False,\n",
        "                height=500\n",
        "            )\n",
        "\n",
        "            # Add hover text for actual scores\n",
        "            fig.update_traces(hovertemplate='<b>%{theta}</b><br>Normalized Ease: %{r:.1f}<br>Actual Score: %{customdata} <extra></extra>',\n",
        "                              customdata=chart_data['actual_score'])\n",
        "\n",
        "            st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "            st.info(\"The **Readability Profile** (Radar Chart) visualizes your text across four metrics on a unified 0-100 'Ease' scale. A score of **100** (outer edge) indicates maximum ease, and **0** (center) indicates maximum difficulty.\")\n",
        "        else:\n",
        "            st.info(\"The text provided is too short or not parsable for full complexity analysis.\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"Document Metrics Summary\")\n",
        "\n",
        "        col_count1, col_count2, col_count3 = st.columns(3)\n",
        "        with col_count1:\n",
        "            st.metric(\"Total Words\", word_count)\n",
        "        with col_count2:\n",
        "            sentence_count = textstat.sentence_count(content_to_analyze)\n",
        "            st.metric(\"Total Sentences\", sentence_count)\n",
        "        with col_count3:\n",
        "            syllable_count = textstat.syllable_count(content_to_analyze)\n",
        "            st.metric(\"Total Syllables\", syllable_count)\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "            <div class=\"key-features\">\n",
        "                <p><b>Key Features:</b> ‚ö° Real-time scoring, üëÅÔ∏è Visual complexity indicators (color-coded cards & radar chart), üìö Comprehensive text metrics.</p>\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "    else:\n",
        "        st.info(\"Upload a document or paste text above and click 'Analyze Content' to generate the professional readability dashboard.\")\n",
        "# =============================================================================\n",
        "#  6. UI SECTION: MODULE 2 - Summarizer & Paraphraser (Full)\n",
        "# =============================================================================\n",
        "def summarizer_paraphraser_ui():\n",
        "    st.markdown(\"<h1>üìö Text Processing</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "    # --- Text input with an explicit 'Send' button ---\n",
        "    st.markdown(\"---\")\n",
        "    col_nlp_text, col_nlp_button = st.columns([6, 1])\n",
        "\n",
        "    default_text = st.session_state.get('last_nlp_input', \"Paste your text here for summarization/paraphrasing...\")\n",
        "\n",
        "    with col_nlp_text:\n",
        "        text_input = st.text_area(\"Paste your text here for summarization/paraphrasing:\", height=200, value=default_text, key=\"nlp_input_area\")\n",
        "    with col_nlp_button:\n",
        "        st.markdown(\"<div style='height: 155px;'></div>\", unsafe_allow_html=True) # Spacer\n",
        "        process_button = st.button(\"Send\", key=\"run_nlp_process\", use_container_width=True)\n",
        "\n",
        "    text_to_process = \"\"\n",
        "\n",
        "    # Logic to trigger processing on button click\n",
        "    if process_button:\n",
        "        if text_input and text_input.strip() != \"Paste your text here for summarization/paraphrasing...\":\n",
        "            st.session_state.original_text = text_input\n",
        "            st.session_state.last_nlp_input = text_input\n",
        "            st.session_state.summary_processed = False\n",
        "            st.session_state.paraphrase_processed = False\n",
        "            # Calculate original readability for the paraphrasing tab\n",
        "            fk_grade, _, _, _ = calculate_readability_scores(text_input)\n",
        "            st.session_state.original_fk_grade = fk_grade\n",
        "        else:\n",
        "            st.warning(\"Please paste some text before clicking 'Send'.\")\n",
        "            return\n",
        "\n",
        "    text_to_process = st.session_state.get('original_text')\n",
        "    if not text_to_process:\n",
        "        st.info(\"Paste text above and click 'Send' to enable summarization and paraphrasing tools.\")\n",
        "        return\n",
        "\n",
        "    # --- UPDATED TABS: Added History ---\n",
        "    sum_tab_main, sum_tab_history = st.tabs([\"Summary Generator\", \"History\"])\n",
        "\n",
        "    with sum_tab_main:\n",
        "        st.subheader(\"Multi-level Summarization\")\n",
        "        col_model, col_length = st.columns([1.5, 2])\n",
        "        with col_model:\n",
        "            sum_model_name = st.selectbox(\"Select Model\", [\"BART\", \"Pegasus\", \"FLAN-T5\"], key=\"sum_model\")\n",
        "        with col_length:\n",
        "            summary_length = st.radio(\"Summary Length\", [\"Short\", \"Medium\", \"Long\"], horizontal=True, key=\"sum_length\")\n",
        "\n",
        "        num_words = len(text_to_process.split())\n",
        "        min_len = max(10, int(num_words * 0.05))\n",
        "        max_len = min(200, int(num_words * 0.5))\n",
        "\n",
        "        if summary_length == \"Short\":\n",
        "            min_len = max(min_len, 20)\n",
        "            max_len = min(max_len, 80)\n",
        "        elif summary_length == \"Medium\":\n",
        "            min_len = max(min_len, 40)\n",
        "            max_len = min(max_len, 120)\n",
        "        else:\n",
        "            min_len = max(min_len, 80)\n",
        "            max_len = min(max_len, 200)\n",
        "\n",
        "        if max_len < min_len + 10:\n",
        "             max_len = min_len + 10\n",
        "\n",
        "        if st.button(f\"Generate {summary_length} Summary\", key=\"run_summarize\"):\n",
        "            with st.spinner(f\"Generating summary using {sum_model_name}...\"):\n",
        "                summarizer = load_summarization_model(sum_model_name)\n",
        "                if summarizer:\n",
        "                    summary_output = summarizer(text_to_process, max_length=max_len, min_length=min_len, do_sample=False)[0]['summary_text']\n",
        "\n",
        "                    r1 = random.uniform(0.35, 0.45)\n",
        "                    rL = random.uniform(0.25, 0.35)\n",
        "\n",
        "                    st.session_state.summary_output = summary_output\n",
        "                    st.session_state.rouge_scores = {'r1': r1, 'rL': rL}\n",
        "                    st.session_state.summary_processed = True\n",
        "                else:\n",
        "                    st.error(\"Model loading failed.\")\n",
        "\n",
        "        if st.session_state.get('summary_processed') and st.session_state.get('summary_output'):\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Comparison: Original vs. Summarized Text\")\n",
        "\n",
        "            col_orig, col_sum = st.columns(2)\n",
        "            with col_orig:\n",
        "                st.markdown(\"**Original Text** (Words: {word_count})\".format(word_count=len(st.session_state.original_text.split())))\n",
        "                st.info(st.session_state.original_text)\n",
        "            with col_sum:\n",
        "                st.markdown(\"**Summarized Text** (Words: {word_count})\".format(word_count=len(st.session_state.summary_output.split())))\n",
        "                st.success(st.session_state.summary_output)\n",
        "\n",
        "            # --- NEW: Word Count Comparison Graph ---\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Word Count Comparison\")\n",
        "            word_count_orig = len(st.session_state.original_text.split())\n",
        "            word_count_sum = len(st.session_state.summary_output.split())\n",
        "\n",
        "            chart_data = pd.DataFrame({\n",
        "                'Text Type': ['Original Text', 'Summarized Text'],\n",
        "                'Word Count': [word_count_orig, word_count_sum]\n",
        "            }).set_index('Text Type')\n",
        "\n",
        "            st.bar_chart(chart_data, use_container_width=True)\n",
        "\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Evaluation: Mock ROUGE Scores Visualized\")\n",
        "\n",
        "            r1_score = st.session_state.rouge_scores['r1']\n",
        "            rL_score = st.session_state.rouge_scores['rL']\n",
        "\n",
        "            rouge_data = pd.DataFrame({\n",
        "                'Metric': ['ROUGE-1 F-Measure', 'ROUGE-L F-Measure'],\n",
        "                'Score': [r1_score, rL_score],\n",
        "            })\n",
        "\n",
        "            rouge_data = rouge_data.set_index('Metric')\n",
        "            st.bar_chart(rouge_data, use_container_width=True)\n",
        "\n",
        "            st.json({\n",
        "                \"rouge1_fmeasure\": f\"{r1_score:.4f}\",\n",
        "                \"rougeL_fmeasure\": f\"{rL_score:.4f}\",\n",
        "                \"Note\": \"ROUGE scores are mocked; true evaluation requires a reference summary.\"\n",
        "            })\n",
        "\n",
        "    with sum_tab_history:\n",
        "        st.subheader(\"Summary History\")\n",
        "        st.markdown(\"\"\"\n",
        "            <div style=\"padding: 10px; border: 1px dashed #ccc; border-radius: 8px;\">\n",
        "                <p>This section is designed to store and display your past summarization results.</p>\n",
        "                <p><strong>Mock History Items:</strong></p>\n",
        "                <ul>\n",
        "                    <li>Summary 1 (BART, Short) - 2025-10-21: R-L 0.32</li>\n",
        "                    <li>Summary 2 (Pegasus, Medium) - 2025-10-20: R-L 0.28</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # --- UPDATED TABS: Added History ---\n",
        "    para_tab_main, para_tab_history = st.tabs([\"Paraphrasing Tool\", \"History\"])\n",
        "\n",
        "    with para_tab_main:\n",
        "        st.subheader(\"Complexity-based Paraphrasing\")\n",
        "        para_col1, para_col2 = st.columns(2)\n",
        "        with para_col1:\n",
        "            complexity_level = st.selectbox(\"Target Complexity Level\", [\"Simplified (Lower Reading Grade)\", \"More Complex (Higher Reading Grade)\", \"Maintain Complexity\"], key=\"para_complexity\")\n",
        "        with para_col2:\n",
        "            para_model_name = st.selectbox(\"Select Model\", [\"FLAN-T5 (Paraphrase)\", \"BART (Paraphrase)\"], key=\"para_model\")\n",
        "\n",
        "        if st.button(\"Generate Paraphrase\", key=\"run_paraphrase\"):\n",
        "            with st.spinner(f\"Generating paraphrase using {para_model_name} for '{complexity_level}'...\"):\n",
        "                model, tokenizer = load_paraphrasing_model(para_model_name)\n",
        "                if model and tokenizer:\n",
        "                    if complexity_level == \"Simplified (Lower Reading Grade)\":\n",
        "                        prompt = f\"Paraphrase the following text to simplify the vocabulary and sentence structure: {text_to_process}\"\n",
        "                    elif complexity_level == \"More Complex (Higher Reading Grade)\":\n",
        "                        prompt = f\"Paraphrase the following text to use more sophisticated vocabulary and longer sentences: {text_to_process}\"\n",
        "                    else:\n",
        "                        prompt = f\"Paraphrase the following text: {text_to_process}\"\n",
        "                    input_ids = tokenizer.encode(prompt, return_tensors='pt', max_length=512, truncation=True)\n",
        "                    outputs = model.generate(input_ids, max_length=int(len(text_to_process.split()) * 2.0), num_beams=5, early_stopping=True)\n",
        "                    paraphrase_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "                    p_fk, _, _, _ = calculate_readability_scores(paraphrase_output)\n",
        "\n",
        "                    st.session_state.paraphrase_output = paraphrase_output\n",
        "                    st.session_state.paraphrase_fk_grade = p_fk\n",
        "                    st.session_state.paraphrase_processed = True\n",
        "                else:\n",
        "                    st.error(\"Model loading failed.\")\n",
        "\n",
        "        if st.session_state.get('paraphrase_processed') and st.session_state.get('paraphrase_output'):\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Comparison: Original vs. Paraphrased\")\n",
        "            col_orig, col_para = st.columns(2)\n",
        "\n",
        "            with col_orig:\n",
        "                st.markdown(\"**Original Text** (F-K Grade: {fk:.1f})\".format(fk=st.session_state.get('original_fk_grade', 0)))\n",
        "                st.info(st.session_state.original_text)\n",
        "            with col_para:\n",
        "                st.markdown(\"**Paraphrased Text** (F-K Grade: {fk:.1f})\".format(fk=st.session_state.paraphrase_fk_grade))\n",
        "                st.success(st.session_state.paraphrase_output)\n",
        "\n",
        "            # --- NEW: Readability Comparison Graph ---\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Readability Shift Visualization (Flesch-Kincaid)\")\n",
        "\n",
        "            original_fk = st.session_state.get('original_fk_grade', 10)\n",
        "            paraphrase_fk = st.session_state.get('paraphrase_fk_grade', original_fk)\n",
        "\n",
        "            # Cap grades at 18 for consistent charting scale (no longer needed to pass to st.line_chart)\n",
        "            max_grade = 18\n",
        "\n",
        "            chart_data = pd.DataFrame({\n",
        "                'Stage': ['Original Text', 'Paraphrased Text'],\n",
        "                'Flesch_Kincaid_Grade': [original_fk, paraphrase_fk]\n",
        "            }).set_index('Stage')\n",
        "\n",
        "            # FIX APPLIED: Removed unsupported arguments (y_label, y_max)\n",
        "            st.line_chart(chart_data, use_container_width=True)\n",
        "            st.markdown(f\"**Y-Axis:** Flesch-Kincaid Grade (Max grade displayed: {max_grade})\")\n",
        "\n",
        "            if complexity_level == \"Simplified (Lower Reading Grade)\":\n",
        "                expected = \"Lower\"\n",
        "                actual_change = \"Decreased\" if paraphrase_fk < original_fk else \"Increased/Maintained\"\n",
        "                st.info(f\"Goal: **{expected}** the Flesch-Kincaid Grade. Actual change: {actual_change}. The graph visualizes this shift.\")\n",
        "            elif complexity_level == \"More Complex (Higher Reading Grade)\":\n",
        "                expected = \"Higher\"\n",
        "                actual_change = \"Increased\" if paraphrase_fk > original_fk else \"Decreased/Maintained\"\n",
        "                st.info(f\"Goal: **{expected}** the Flesch-Kincaid Grade. Actual change: {actual_change}. The graph visualizes this shift.\")\n",
        "            else:\n",
        "                st.info(\"The graph visualizes the change in readability after paraphrasing.\")\n",
        "\n",
        "    with para_tab_history:\n",
        "        st.subheader(\"Paraphrasing History\")\n",
        "        st.markdown(\"\"\"\n",
        "            <div style=\"padding: 10px; border: 1px dashed #ccc; border-radius: 8px;\">\n",
        "                <p>This section is designed to store and display your past paraphrasing results.</p>\n",
        "                <p><strong>Mock History Items:</strong></p>\n",
        "                <ul>\n",
        "                    <li>Paraphrase 1 (Simplified) - 2025-10-21: FK Grade 8.5</li>\n",
        "                    <li>Paraphrase 2 (Complex) - 2025-10-19: FK Grade 13.2</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#  7. UI SECTION: CHAT UI (Full)\n",
        "# =============================================================================\n",
        "def real_time_chat_ui():\n",
        "    st.markdown(\"<h1>üí¨ Real-Time Chat Assistant</h1>\", unsafe_allow_html=True)\n",
        "    st.info(\"This section provides real-time chat functionality, including the ability to upload files for context-aware conversation.\")\n",
        "\n",
        "    # Initialize states\n",
        "    if 'messages' not in st.session_state: st.session_state.messages = [{'role': 'assistant', 'content': 'Hello! How can I help you today? You can upload a document for a context-aware chat.'}]\n",
        "    if 'chat_history' not in st.session_state: st.session_state.chat_history = []\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.header(\"Chat Controls\")\n",
        "\n",
        "        # New Chat Button\n",
        "        if st.button(\"‚ûï New Chat\", key=\"new_chat\"):\n",
        "            # Save current chat to history if it has more than just the greeting\n",
        "            if len(st.session_state.messages) > 1: st.session_state.chat_history.append(st.session_state.messages)\n",
        "            st.session_state.messages = [{'role': 'assistant', 'content': 'Hello! How can I help you today? You can upload a document for a context-aware chat.'}]\n",
        "            st.session_state.chat_context = None\n",
        "            st.rerun()\n",
        "\n",
        "        # Delete All Chat History Button (New Feature)\n",
        "        if st.button(\"üóëÔ∏è Delete All History\", key=\"delete_history\"):\n",
        "            st.session_state.chat_history = []\n",
        "            st.session_state.messages = [{'role': 'assistant', 'content': 'Chat history deleted. New session started.'}]\n",
        "            st.session_state.chat_context = None\n",
        "            st.rerun()\n",
        "\n",
        "        st.subheader(\"Recent Chats\")\n",
        "        for i, chat in enumerate(st.session_state.chat_history):\n",
        "            # Extract the first user prompt as the title\n",
        "            user_prompt = next((msg['content'] for msg in chat if msg['role'] == 'user'), 'Chat')\n",
        "            if st.button(f\"üìú {user_prompt[:30]}...\", key=f\"chat_{i}\"):\n",
        "                st.session_state.messages = chat; st.rerun()\n",
        "\n",
        "    # Display Messages\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message['role']): st.markdown(message['content'])\n",
        "\n",
        "    # File Uploader for Context\n",
        "    uploaded_context_file = st.file_uploader(\"Upload Document for Context (+)\", type=[\"txt\"], key=\"chat_file_upload\")\n",
        "\n",
        "    # Handle context loading\n",
        "    if uploaded_context_file and 'chat_context' not in st.session_state:\n",
        "        st.session_state.chat_context = uploaded_context_file.read().decode(\"utf-8\")\n",
        "        st.info(\"Document uploaded. Your next chat questions will use this document as context.\")\n",
        "\n",
        "    if 'chat_context' in st.session_state and st.session_state.chat_context:\n",
        "        st.success(f\"Context loaded: {len(st.session_state.chat_context.split())} words.\")\n",
        "\n",
        "    # Predefined Q&A (add more here as needed)\n",
        "    predefined_qa = {\n",
        "        \"what is text summarization?\": \"Text summarization is the task of creating a shorter version of a text document or article while retaining the most important information.\",\n",
        "        \"how does paraphrasing work?\": \"Paraphrasing involves rephrasing a text using different words and sentence structures while keeping the original meaning intact. It can be used to simplify complex text or make it more sophisticated.\",\n",
        "        \"what are readability scores?\": \"Readability scores are metrics that estimate the difficulty a reader will have understanding a text. Examples include Flesch-Kincaid Grade Level, Gunning Fog Index, and Flesch Reading Ease.\",\n",
        "        \"what are summarization and paraphrasing models?\": \"Summarization and paraphrasing models are types of large language models (LLMs) or natural language processing (NLP) models trained for specific text generation tasks. Summarization models create concise versions of texts, while paraphrasing models rephrase texts to alter complexity or style.\",\n",
        "        \"hi\": \"Hello there! How can I assist you today?\",\n",
        "        \"hello\": \"Hi! What can I do for you?\"\n",
        "    }\n",
        "\n",
        "    # Mock Response Logic\n",
        "    def get_bot_response(user_prompt, context=None):\n",
        "        time.sleep(1) # Simulate thinking time\n",
        "\n",
        "        # Check for predefined answers (case-insensitive and strip whitespace)\n",
        "        cleaned_prompt = user_prompt.strip().lower()\n",
        "        if cleaned_prompt in predefined_qa:\n",
        "            return predefined_qa[cleaned_prompt]\n",
        "\n",
        "        # Fallback to original mock response if no predefined answer\n",
        "        if context:\n",
        "            return f\"**Context-Aware Mock Response:** Based on your document ({len(context.split())} words), I interpret your question about '{user_prompt[:20]}...' as requiring a complex answer. [Replace with actual LLM call and context window management]\"\n",
        "        else:\n",
        "            return f\"**Real-Time Mock Response:** This is a general response to: '{user_prompt[:20]}...'. [Replace with actual LLM call]\"\n",
        "\n",
        "    # Chat Input\n",
        "    if prompt := st.chat_input(\"Ask me anything...\"):\n",
        "        st.session_state.messages.append({'role': 'user', 'content': prompt})\n",
        "        with st.chat_message('user'): st.markdown(prompt)\n",
        "\n",
        "        with st.chat_message('assistant'):\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                context = st.session_state.get('chat_context')\n",
        "                response = get_bot_response(prompt, context)\n",
        "                st.markdown(response)\n",
        "        st.session_state.messages.append({'role': 'assistant', 'content': response})\n",
        "\n",
        "# =============================================================================\n",
        "#  8. FORGOT PASSWORD UI (UPDATED WITH PERSISTENT MOCK OTP)\n",
        "# =============================================================================\n",
        "def forgot_password_ui():\n",
        "    st.subheader(\"Forgot Password (Mock OTP)\")\n",
        "\n",
        "    if 'forgot_stage' not in st.session_state: st.session_state.forgot_stage = 0\n",
        "    if 'mock_otp_code' not in st.session_state: st.session_state.mock_otp_code = None\n",
        "\n",
        "    if st.session_state.forgot_stage == 0:\n",
        "        with st.form(\"forgot_password_email_form\", clear_on_submit=True):\n",
        "            st.markdown(\"##### Step 1: Request Code\")\n",
        "            forgot_email = st.text_input(\"Enter your Email\", key=\"forgot_email_0\")\n",
        "\n",
        "            if st.form_submit_button(\"Send Mock Reset Code\"):\n",
        "                if not user_exists(forgot_email):\n",
        "                    st.error(\"Email not found. Please check your email address.\")\n",
        "                    st.session_state.mock_otp_code = None # Clear code on failure\n",
        "                else:\n",
        "                    otp_code = generate_and_store_otp(forgot_email)\n",
        "                    st.session_state.forgot_email = forgot_email\n",
        "                    st.session_state.forgot_stage = 1\n",
        "                    # Store the OTP in session state to persist the warning\n",
        "                    st.session_state.mock_otp_code = otp_code\n",
        "                    st.success(f\"A mock reset code has been 'sent' to {forgot_email}. It expires in {MOCK_OTP_DURATION_MINUTES} minutes.\")\n",
        "                    st.rerun() # Rerun to display Step 2 form\n",
        "\n",
        "    if st.session_state.get('forgot_stage') == 1:\n",
        "        # Display persistent mock code warning at the top of the form\n",
        "        if st.session_state.mock_otp_code:\n",
        "             st.markdown(f\"\"\"\n",
        "                <div class=\"mock-code-warning\">\n",
        "                    üö® **Mock Code (Copy this): {st.session_state.mock_otp_code}** </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        st.markdown(f\"##### Step 2: Enter Code and New Password for {st.session_state.forgot_email}\")\n",
        "        with st.form(\"forgot_password_reset_form\", clear_on_submit=True):\n",
        "            user_otp = st.text_input(\"Enter Reset Code\", key=\"user_otp\")\n",
        "            new_pass = st.text_input(\"Enter New Password (Min 6 chars)\", type=\"password\", key=\"forgot_new_pass_1\") # Password length note added\n",
        "            confirm_new_pass = st.text_input(\"Confirm New Password\", type=\"password\", key=\"forgot_confirm_pass_1\")\n",
        "\n",
        "            if st.form_submit_button(\"Reset Password\"):\n",
        "                if new_pass != confirm_new_pass:\n",
        "                    st.error(\"New passwords do not match.\")\n",
        "                elif len(new_pass) < 6:\n",
        "                    st.error(\"Password must be at least 6 characters long.\")\n",
        "                elif not verify_otp(st.session_state.forgot_email, user_otp):\n",
        "                    st.error(\"Invalid or expired reset code. Please request a new one.\")\n",
        "                else:\n",
        "                    # Success Path\n",
        "                    message = update_password(st.session_state.forgot_email, new_pass)\n",
        "                    st.success(message + \" You can now log in.\")\n",
        "                    st.session_state.forgot_stage = 0\n",
        "                    del st.session_state.forgot_email\n",
        "                    del st.session_state.mock_otp_code # Clear mock code on success\n",
        "                    time.sleep(2)\n",
        "                    st.rerun()\n",
        "\n",
        "        # Allow user to go back to request a new code\n",
        "        if st.button(\"Go back to request new code\"):\n",
        "            st.session_state.forgot_stage = 0\n",
        "            if 'forgot_email' in st.session_state: del st.session_state.forgot_email\n",
        "            if 'mock_otp_code' in st.session_state: del st.session_state.mock_otp_code\n",
        "            st.rerun()\n",
        "\n",
        "# =============================================================================\n",
        "#  9. UI SECTION: ADMIN DASHBOARD (NEW FEATURE)\n",
        "# =============================================================================\n",
        "def admin_dashboard_ui():\n",
        "    st.markdown(\"<h1>üëë Admin Dashboard: User Management</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "    tab_view, tab_add = st.tabs([\"View & Delete Users\", \"Add New User\"])\n",
        "\n",
        "    with tab_view:\n",
        "        st.subheader(\"Current Users\")\n",
        "\n",
        "        user_data = get_all_users()\n",
        "\n",
        "        if not user_data.empty:\n",
        "            st.dataframe(user_data, use_container_width=True, hide_index=True)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"Delete User\")\n",
        "\n",
        "            # Filter out the current admin from deletion list to prevent lockout\n",
        "            users_to_delete = user_data[user_data['email'] != st.session_state.user_email]['email'].tolist()\n",
        "\n",
        "            if not users_to_delete:\n",
        "                st.warning(\"Only the current Admin user exists. Cannot delete the only Admin.\")\n",
        "                return\n",
        "\n",
        "            email_to_delete = st.selectbox(\"Select User Email to Delete\", users_to_delete, key=\"delete_email_select\")\n",
        "\n",
        "            if st.button(f\"Permanently Delete User: {email_to_delete}\", key=\"run_delete_user\"):\n",
        "                if email_to_delete == st.session_state.user_email:\n",
        "                    st.error(\"You cannot delete your own active Admin account.\")\n",
        "                else:\n",
        "                    delete_user(email_to_delete)\n",
        "                    st.success(f\"User '{email_to_delete}' has been deleted.\")\n",
        "                    st.rerun() # Refresh list\n",
        "\n",
        "        else:\n",
        "            st.info(\"No users found in the database.\")\n",
        "\n",
        "    with tab_add:\n",
        "        st.subheader(\"Register New User\")\n",
        "        with st.form(\"admin_register_form\"):\n",
        "            new_email = st.text_input(\"Email\", key=\"admin_reg_email\")\n",
        "            new_username = st.text_input(\"Username\", key=\"admin_reg_username\") # NEW FIELD\n",
        "            new_password = st.text_input(\"New Password (Min 6 chars)\", type=\"password\", key=\"admin_reg_pass\")\n",
        "            confirm_password = st.text_input(\"Confirm Password\", type=\"password\", key=\"admin_reg_confirm\")\n",
        "            role = st.selectbox(\"Role\", [\"General User\", \"Admin\"], key=\"admin_reg_role_select\")\n",
        "\n",
        "            if st.form_submit_button(\"Register New User\"):\n",
        "                if new_password != confirm_password:\n",
        "                    st.error(\"Passwords do not match.\")\n",
        "                elif len(new_password) < 6: # New Validation\n",
        "                    st.error(\"Password must be at least 6 characters long.\")\n",
        "                elif not new_username.strip():\n",
        "                    st.error(\"Username cannot be empty.\")\n",
        "                else:\n",
        "                    # Pass username to the registration function\n",
        "                    message = register_user(new_email, new_username, new_password, role) # PASS USERNAME\n",
        "                    if \"successfully\" in message:\n",
        "                        st.success(message + \" New user added.\")\n",
        "                        st.rerun()\n",
        "                    else:\n",
        "                        st.warning(message)\n",
        "\n",
        "# =============================================================================\n",
        "#  10. MAIN AUTHENTICATION ROUTER\n",
        "# =============================================================================\n",
        "\n",
        "# Initialize session states\n",
        "if 'token' not in st.session_state: st.session_state.token = None\n",
        "if 'current_view' not in st.session_state: st.session_state.current_view = 'Readability Analysis'\n",
        "if 'forgot_stage' not in st.session_state: st.session_state.forgot_stage = 0\n",
        "if 'messages' not in st.session_state: st.session_state.messages = [{'role': 'assistant', 'content': 'Hello! How can I help you today?'}]\n",
        "if 'chat_history' not in st.session_state: st.session_state.chat_history = []\n",
        "if 'theme' not in st.session_state: st.session_state.theme = 'Light'\n",
        "if 'summary_processed' not in st.session_state: st.session_state.summary_processed = False\n",
        "if 'paraphrase_processed' not in st.session_state: st.session_state.paraphrase_processed = False\n",
        "if 'mock_otp_code' not in st.session_state: st.session_state.mock_otp_code = None\n",
        "if 'last_nlp_input' not in st.session_state: st.session_state.last_nlp_input = \"\"\n",
        "if 'readability_run' not in st.session_state: st.session_state.readability_run = False\n",
        "if 'original_fk_grade' not in st.session_state: st.session_state.original_fk_grade = None\n",
        "if 'paraphrase_fk_grade' not in st.session_state: st.session_state.paraphrase_fk_grade = None\n",
        "if 'show_forgot_password' not in st.session_state: st.session_state.show_forgot_password = False\n",
        "\n",
        "\n",
        "init_db()\n",
        "payload = decode_token(st.session_state.token)\n",
        "\n",
        "if payload is None:\n",
        "    st.session_state.token = None\n",
        "    st.session_state.forgot_stage = st.session_state.get('forgot_stage', 0)\n",
        "\n",
        "    # Ensure all processing flags are reset on logout/no login\n",
        "    st.session_state.summary_processed = False\n",
        "    st.session_state.paraphrase_processed = False\n",
        "    st.session_state.readability_run = False\n",
        "\n",
        "    _, main_content, _ = st.columns([1, 1.5, 1])\n",
        "    with main_content:\n",
        "        st.markdown(\"<h1>‚û° User Authentication</h1>\", unsafe_allow_html=True)\n",
        "        login_tab, register_tab = st.tabs([\"Login\", \"Register\"]) # Removed forgot_pass_tab\n",
        "\n",
        "        with login_tab:\n",
        "            if not st.session_state.get('show_forgot_password', False):\n",
        "                with st.form(\"login_form\"):\n",
        "                    email = st.text_input(\"Email\", placeholder=\"Enter your Email\")\n",
        "                    password = st.text_input(\"Password\", type=\"password\", placeholder=\"*****\")\n",
        "                    if st.form_submit_button(\"Sign In\"):\n",
        "                        token = authenticate_user(email, password)\n",
        "                        if token:\n",
        "                            st.session_state.token = token\n",
        "                            st.session_state.messages = [{'role': 'assistant', 'content': 'Hello! How can I help you today?'}]\n",
        "                            st.session_state.chat_history = []\n",
        "                            st.session_state.forgot_stage = 0 # Reset stage on login\n",
        "                            st.session_state.show_forgot_password = False # Reset on successful login\n",
        "                            if 'mock_otp_code' in st.session_state: del st.session_state.mock_otp_code # Clear code on successful login\n",
        "                            st.rerun()\n",
        "                        else:\n",
        "                            st.error(\"Invalid email or password.\")\n",
        "\n",
        "                # Added Forgot Password button here outside the form\n",
        "                if st.button(\"Forgot Password?\"):\n",
        "                    st.session_state.forgot_stage = 0 # Reset stage to 0 to show email input\n",
        "                    st.session_state.show_forgot_password = True\n",
        "                    st.rerun() # Rerun to switch form\n",
        "\n",
        "            if st.session_state.get('show_forgot_password', False):\n",
        "                forgot_password_ui() # Call the forgot password UI function\n",
        "\n",
        "        with register_tab:\n",
        "            with st.form(\"register_form\"):\n",
        "                new_email = st.text_input(\"Email\", key=\"reg_email\")\n",
        "                new_username = st.text_input(\"Username\", key=\"reg_username\") # NEW FIELD\n",
        "                new_password = st.text_input(\"New Password (Min 6 chars)\", type=\"password\", key=\"reg_pass\")\n",
        "                confirm_password = st.text_input(\"Confirm Password\", type=\"password\", key=\"reg_confirm\")\n",
        "                role = st.selectbox(\"Role\", [\"General User\", \"Admin\"], key=\"reg_role_select\")\n",
        "                if st.form_submit_button(\"Register\"):\n",
        "                    if new_password != confirm_password:\n",
        "                        st.error(\"Passwords do not match.\")\n",
        "                    elif len(new_password) < 6:\n",
        "                        st.error(\"Password must be at least 6 characters long.\") # NEW VALIDATION\n",
        "                    elif not new_username.strip():\n",
        "                        st.error(\"Username cannot be empty.\")\n",
        "                    else:\n",
        "                        message = register_user(new_email, new_username, new_password, role) # PASS USERNAME\n",
        "                        if \"successfully\" in message: st.success(message)\n",
        "                        else: st.warning(message)\n",
        "\n",
        "\n",
        "else: # User is logged in\n",
        "    role = payload['role']\n",
        "    st.session_state.user_email = payload['sub']\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.success(f\"Logged in as: {st.session_state.user_email}\")\n",
        "        st.write(f\"Your role is: **{role}**\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        st.subheader(\"Navigation\")\n",
        "        if role.lower() == \"admin\":\n",
        "            if st.button(\"Admin Dashboard\", key=\"nav_admin\"):\n",
        "                st.session_state.current_view = \"Admin Dashboard\"\n",
        "            st.markdown(\"---\") # Separator for admin section\n",
        "\n",
        "        if st.button(\"Readability Analysis\", key=\"nav_readability\"):\n",
        "            st.session_state.current_view = \"Readability Analysis\"\n",
        "        if st.button(\"Text Processing\", key=\"nav_text_processing\"):\n",
        "            st.session_state.current_view = \"Text Processing\"\n",
        "        if st.button(\"Chat Assistant\", key=\"nav_chat\"):\n",
        "             st.session_state.current_view = \"Chat Assistant\"\n",
        "\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        if st.button(\"Logout\"):\n",
        "            st.session_state.token = None\n",
        "            st.session_state.current_view = 'Readability Analysis'\n",
        "            # Clear all session states relevant to user data/processing\n",
        "            st.session_state.messages = []\n",
        "            st.session_state.chat_history = []\n",
        "            if 'chat_context' in st.session_state: del st.session_state.chat_context\n",
        "            st.session_state.readability_run = False\n",
        "            st.session_state.show_forgot_password = False # Ensure this is reset on logout\n",
        "            st.rerun()\n",
        "\n",
        "    # Render content based on role and selected view\n",
        "    if role.lower() == \"admin\" and st.session_state.current_view == \"Admin Dashboard\":\n",
        "        admin_dashboard_ui()\n",
        "    elif st.session_state.current_view == \"Readability Analysis\":\n",
        "        readability_analysis_ui()\n",
        "    elif st.session_state.current_view == \"Text Processing\":\n",
        "        summarizer_paraphraser_ui()\n",
        "    elif st.session_state.current_view == \"Chat Assistant\":\n",
        "        real_time_chat_ui()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7swWXCiK36C",
        "outputId": "ef01e004-b6b2-45e1-eaec-482f816da9fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3 ‚Äì Run Streamlit via Pyngrok\n",
        "ngrok.kill() # Ensure all ngrok processes are stopped\n",
        "public_url = ngrok.connect(8502)\n",
        "print(f\"üåç Public URL: {public_url}\")\n",
        "!streamlit run app1.py --server.port 8502 --server.headless true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3conKtsLEhq",
        "outputId": "4157318f-b47f-4f02-fb09-27b587a33c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç Public URL: NgrokTunnel: \"https://steedless-wayne-unreproached.ngrok-free.dev\" -> \"http://localhost:8502\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.53.94.230:8502\u001b[0m\n",
            "\u001b[0m\n",
            "2025-10-23 13:06:00.801252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761224760.963371     655 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761224761.034307     655 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761224761.076892     655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761224761.079425     655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761224761.079484     655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761224761.079492     655 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-23 13:06:01.096106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ]
    }
  ]
}